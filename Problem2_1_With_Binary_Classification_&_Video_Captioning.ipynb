{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb94e55ece1a473a8cb40e2a5d0dab60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".mp4",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_879a865cf746455a91b1cf5177d349bb",
            "metadata": [
              {
                "name": "my.mp4",
                "type": "video/mp4",
                "size": 1570024,
                "lastModified": 1730311024551
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_64d433d25a504989a24c23522ccabeba"
          }
        },
        "879a865cf746455a91b1cf5177d349bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d433d25a504989a24c23522ccabeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Required Libraries (Run in Colab or a new environment)\n",
        "!pip install torch transformers huggingface_hub opencv-python numpy ipywidgets scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGueTLLl55g-",
        "outputId": "3295c133-b591-4121-a428-33d9374ca266"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import logging\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Initialize logging for real-time feedback\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n"
      ],
      "metadata": {
        "id": "V4p0OoPd57Bc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    FRAME_SIZE = (224, 224)\n",
        "    NUM_FRAMES = 32\n",
        "    CNN_FEATURE_DIM = 512\n",
        "    LSTM_HIDDEN_DIM = 256\n",
        "    NUM_CLASSES = 2  # Binary classification (0 or 1)\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "id": "wG-bOVH759Xz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionFeatureExtractor:\n",
        "    def __init__(self, model_name=\"google/vit-base-patch16-224\"):\n",
        "        try:\n",
        "            self.feature_extractor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)\n",
        "            self.model = AutoModelForImageClassification.from_pretrained(model_name).to(Config.DEVICE)\n",
        "            logging.info(\"Diffusion model and feature extractor loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(\"Error loading model:\", e)\n",
        "            raise\n",
        "\n",
        "    def extract_features_with_reconstruction_error(self, frames):\n",
        "        inputs = self.feature_extractor(images=frames, return_tensors=\"pt\", do_rescale=False).to(Config.DEVICE)\n",
        "\n",
        "        # Original frame features\n",
        "        with torch.no_grad():\n",
        "            original_features = self.model(**inputs).logits\n",
        "\n",
        "        # Perturb frames and reprocess to simulate reconstruction\n",
        "        reconstructed_frames = frames * 0.95\n",
        "        reconstructed_inputs = self.feature_extractor(images=reconstructed_frames, return_tensors=\"pt\", do_rescale=False).to(Config.DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            reconstructed_features = self.model(**reconstructed_inputs).logits\n",
        "        reconstruction_error = (original_features - reconstructed_features).abs()\n",
        "\n",
        "        # Flatten and interpolate directly to target dimensions\n",
        "        reconstruction_error = reconstruction_error.flatten(start_dim=1)\n",
        "        reconstruction_error = reconstruction_error.view(Config.NUM_FRAMES, 1, -1, 1)\n",
        "        reconstruction_error = F.interpolate(reconstruction_error, size=(32, 32), mode='bilinear', align_corners=False)\n",
        "\n",
        "        return reconstruction_error\n"
      ],
      "metadata": {
        "id": "RWoEIJLb5_xB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_to_frames(video_path, frame_size=(224, 224), num_frames=32):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if frame_count < num_frames:\n",
        "        logging.warning(f\"Video only has {frame_count} frames, expected {num_frames}.\")\n",
        "\n",
        "    while cap.isOpened() and len(frames) < num_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, frame_size)\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    frames = np.array(frames) / 255.0\n",
        "    logging.info(f\"Processed {len(frames)} frames from the video.\")\n",
        "    return frames\n"
      ],
      "metadata": {
        "id": "WtxwZbW56Asi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(32 * 8 * 8, Config.CNN_FEATURE_DIM)\n",
        "        self.lstm = nn.LSTM(Config.CNN_FEATURE_DIM, Config.LSTM_HIDDEN_DIM, batch_first=True)\n",
        "        self.classifier = nn.Linear(Config.LSTM_HIDDEN_DIM, Config.NUM_CLASSES)  # Binary output\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_frames, channels, height, width = x.size()\n",
        "        cnn_out = []\n",
        "        for t in range(num_frames):\n",
        "            frame_features = x[:, t]\n",
        "            cnn_out.append(self.fc(self.flatten(self.cnn(frame_features))))\n",
        "        cnn_out = torch.stack(cnn_out, dim=1)\n",
        "        lstm_out, _ = self.lstm(cnn_out)\n",
        "        final_output = self.classifier(lstm_out[:, -1, :])\n",
        "        return final_output\n"
      ],
      "metadata": {
        "id": "VzE-dc436CuK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    logging.info(f\"Metrics - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def calculate_reconstruction_error(original_features, reconstructed_features):\n",
        "    error = (original_features - reconstructed_features).abs().mean().item()\n",
        "    return error\n"
      ],
      "metadata": {
        "id": "x8bxqrd86EnB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(video_path, y_true):\n",
        "    frames = video_to_frames(video_path)\n",
        "    if len(frames) == 0:\n",
        "        logging.error(\"Error: No frames were extracted from the video.\")\n",
        "        return\n",
        "\n",
        "    diffusion_model = DiffusionFeatureExtractor()\n",
        "    reconstruction_error_features = diffusion_model.extract_features_with_reconstruction_error(frames)\n",
        "    reconstruction_error_features = reconstruction_error_features.unsqueeze(0).to(Config.DEVICE)\n",
        "\n",
        "    cnn_lstm_model = CNNLSTMModel().to(Config.DEVICE)\n",
        "    cnn_lstm_model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = cnn_lstm_model(reconstruction_error_features)\n",
        "    predicted_class = torch.argmax(prediction, dim=1).item()\n",
        "\n",
        "    accuracy, precision, recall, f1 = calculate_metrics([y_true], [predicted_class])\n",
        "    logging.info(f\"Binary Classification Result: {predicted_class}\")\n",
        "\n",
        "    original_features = diffusion_model.model(**diffusion_model.feature_extractor(images=frames, return_tensors=\"pt\", do_rescale=False)).logits\n",
        "    reconstructed_frames = frames * 0.95\n",
        "    reconstructed_features = diffusion_model.model(**diffusion_model.feature_extractor(images=reconstructed_frames, return_tensors=\"pt\", do_rescale=False)).logits\n",
        "    reconstruction_error = calculate_reconstruction_error(original_features, reconstructed_features)\n",
        "    logging.info(f\"Reconstruction Error (Anomaly Detection): {reconstruction_error:.4f}\")\n",
        "\n",
        "    return predicted_class, accuracy, precision, recall, f1, reconstruction_error\n"
      ],
      "metadata": {
        "id": "Jl7CFcqx61Jd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_captioning_model():\n",
        "    return pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def initialize_summarization_model():\n",
        "    return pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "captioning_model = initialize_captioning_model()\n",
        "summarization_model = initialize_summarization_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDrVttyW6Gtj",
        "outputId": "60fa401f-c158-48d3-9e72-017a8b491284"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_description(video_path, captioning_model, frame_sample_rate=10):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    descriptions = []\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    success, frame_id = True, 0\n",
        "\n",
        "    while success:\n",
        "        success, frame = cap.read()\n",
        "        if frame_id % frame_sample_rate == 0 and success:\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            caption = captioning_model(frame_rgb)[0][\"generated_text\"]\n",
        "            descriptions.append(caption)\n",
        "        frame_id += 1\n",
        "\n",
        "    cap.release()\n",
        "    return descriptions\n"
      ],
      "metadata": {
        "id": "OqmXRqF76Ila"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_descriptions(descriptions, summarization_model):\n",
        "    \"\"\"\n",
        "    Summarize the descriptions of frames into an overall video summary.\n",
        "\n",
        "    Args:\n",
        "        descriptions (list): List of frame descriptions.\n",
        "        summarization_model (pipeline): Hugging Face summarization pipeline.\n",
        "\n",
        "    Returns:\n",
        "        summary (str): Summarized description of the video content.\n",
        "    \"\"\"\n",
        "    text = \" \".join(descriptions)\n",
        "    summary = summarization_model(\n",
        "        text,\n",
        "        max_length=50,  # Adjust based on the desired summary length\n",
        "        min_length=20,  # Minimum length for summarization\n",
        "        max_new_tokens=50,  # Controls the number of new tokens generated\n",
        "        do_sample=False\n",
        "    )[0][\"summary_text\"]\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "Jv3FV5Gr6MJx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_with_description(video_path, y_true):\n",
        "    # Run original inference\n",
        "    predicted_class, accuracy, precision, recall, f1, reconstruction_error = run_pipeline(video_path, y_true)\n",
        "\n",
        "    # Generate frame descriptions and a summary\n",
        "    descriptions = generate_video_description(video_path, captioning_model)\n",
        "    video_summary = summarize_descriptions(descriptions, summarization_model)\n",
        "\n",
        "    # Output results\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "    print(f\"Metrics - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "    print(f\"Reconstruction Error: {reconstruction_error:.4f}\")\n",
        "    print(\"Frame Descriptions:\", descriptions)\n",
        "    print(\"Video Summary:\", video_summary)\n",
        "\n",
        "    return predicted_class, accuracy, precision, recall, f1, reconstruction_error, descriptions, video_summary\n"
      ],
      "metadata": {
        "id": "G3vmL2YG6Oei"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image  # Import PIL to handle image conversion\n",
        "\n",
        "def generate_video_description(video_path, captioning_model, frame_sample_rate=10):\n",
        "    \"\"\"\n",
        "    Generate descriptions for key frames in the video.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        captioning_model (pipeline): Hugging Face image captioning pipeline.\n",
        "        frame_sample_rate (int): Interval of frames to sample. Higher values mean fewer sampled frames.\n",
        "\n",
        "    Returns:\n",
        "        descriptions (list): List of frame descriptions.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    descriptions = []\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    success, frame_id = True, 0\n",
        "\n",
        "    while success:\n",
        "        success, frame = cap.read()\n",
        "        if frame_id % frame_sample_rate == 0 and success:\n",
        "            # Convert the frame to RGB and then to a PIL image\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            pil_image = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Generate a description for the frame\n",
        "            caption = captioning_model(pil_image)[0][\"generated_text\"]\n",
        "            descriptions.append(caption)\n",
        "        frame_id += 1\n",
        "\n",
        "    cap.release()\n",
        "    return descriptions\n"
      ],
      "metadata": {
        "id": "4TISKCDD7yGi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_predict_with_description(y_true=1):\n",
        "    upload_button = widgets.FileUpload(accept=\".mp4\", multiple=False)\n",
        "    display(upload_button)\n",
        "\n",
        "    def on_upload_change(change):\n",
        "        for name, file_info in upload_button.value.items():\n",
        "            video_path = f'/content/{name}'\n",
        "            with open(video_path, 'wb') as f:\n",
        "                f.write(file_info['content'])\n",
        "\n",
        "            logging.info(\"Running pipeline on uploaded video...\")\n",
        "\n",
        "            # Run the pipeline with description generation\n",
        "            predicted_class, accuracy, precision, recall, f1, reconstruction_error, descriptions, video_summary = run_pipeline_with_description(video_path, y_true)\n",
        "\n",
        "            # Display the results\n",
        "            print(f\"Predicted Class: {predicted_class}\")\n",
        "            print(f\"Metrics - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "            print(f\"Reconstruction Error: {reconstruction_error:.4f}\")\n",
        "            print(\"Frame Descriptions:\", descriptions)\n",
        "            print(\"Video Summary:\", video_summary)\n",
        "\n",
        "    # Trigger the function when the file is uploaded\n",
        "    upload_button.observe(on_upload_change, names='value')\n",
        "\n",
        "# Run this function to display the upload button\n",
        "upload_and_predict_with_description(y_true=1)  # Set y_true to the ground truth label of the uploaded video\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "cb94e55ece1a473a8cb40e2a5d0dab60",
            "879a865cf746455a91b1cf5177d349bb",
            "64d433d25a504989a24c23522ccabeba"
          ]
        },
        "id": "xbD0qqnu6SI0",
        "outputId": "c4a76d41-c2a5-4d03-9d53-9a4bf620f689"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.mp4', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb94e55ece1a473a8cb40e2a5d0dab60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-10-31 05:06:11,793 - INFO - Running pipeline on uploaded video...\n",
            "2024-10-31 05:06:11,934 - INFO - Processed 32 frames from the video.\n",
            "2024-10-31 05:06:12,590 - INFO - Diffusion model and feature extractor loaded successfully.\n",
            "2024-10-31 05:06:56,059 - INFO - Metrics - Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "2024-10-31 05:06:56,060 - INFO - Binary Classification Result: 1\n",
            "2024-10-31 05:07:39,070 - INFO - Reconstruction Error (Anomaly Detection): 0.0250\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}